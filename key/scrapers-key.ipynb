{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library = an 'addon' or 'extension' to Python\n",
    "\n",
    "* **`requests`** : download the website\n",
    "* **`BeautifulSoup`** : pick out the important parts.\n",
    "* **`pandas`** : just for exporting the csv in the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requests` methods we'll use:\n",
    "<br>➡ `requests.get(webpage)` : download the page, where `webpage` is the URL of the page\n",
    "<br>➡ `.text` : get the HTML out of the download\n",
    "\n",
    "`BeautifulSoup` methods we'll use:\n",
    "<br>➡ `BeautifulSoup(downloaded_page_text)` : read the downloaded page\n",
    "<br>➡ `.select` : select the elements we want to get based on their tags or attributes\n",
    "<br>➡ `.get()` : get an attribute value\n",
    "<br>➡ `.text` : get the content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/html-syntax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also: \n",
    "* [CSS selector reference](https://www.w3schools.com/cssref/css_selectors.asp)\n",
    "* [BeautifulSoup reference](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "* [Requests reference](https://realpython.com/python-requests/#the-get-request)\n",
    "* [Pandas export csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste these in the cell beneath \n",
    "\n",
    "`import requests`<br> \n",
    "`import pandas`<br> \n",
    "`from bs4 import BeautifulSoup as bs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPER #1 : focus on loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all the headlines in the last 5 pages of the 'Today in focus' page of The Guardian https://www.theguardian.com/news/series/todayinfocus\n",
    "<br>➡ **Important**: we need to take the pagination into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download and read the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the website as a string in variable `URL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.theguardian.com/news/series/todayinfocus?page=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the website with `requests.get()` and save it into variable `website_request`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_request = requests.get(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the HTML of the website using `.text` and save it into variable `website_content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_content = website_request.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the website with `BeautifulSoup` and save it into variable `website_read`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_read = bs(website_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. scrape all the headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `website_read.select()` method here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"js-headline-text\">The five brothers forced apart by the war in Syria</span>,\n",
       " <span class=\"js-headline-text\">Naomi Klein on how politics can solve the climate crisis</span>,\n",
       " <span class=\"js-headline-text\">Are Fox News and Donald Trump falling out of love?</span>,\n",
       " <span class=\"js-headline-text\">Is this the end of the road for remainers?</span>,\n",
       " <span class=\"js-headline-text\">How did a town in West Virginia become the opioid capital of the US?</span>,\n",
       " <span class=\"js-headline-text\">Naming and shaming the polluters</span>,\n",
       " <span class=\"js-headline-text\">Will parliament vote for a Brexit deal?</span>,\n",
       " <span class=\"js-headline-text\">On the frontline as US troops leave northern Syria</span>,\n",
       " <span class=\"js-headline-text\">Hong Kong: the story of one protester</span>,\n",
       " <span class=\"js-headline-text\">What is the truth about vaping?</span>,\n",
       " <span class=\"js-headline-text\">A fatal crash and the problem of diplomatic immunity</span>,\n",
       " <span class=\"js-headline-text\">Brexit and the Irish border: is there a solution?</span>,\n",
       " <span class=\"js-headline-text\">Shell, Nigeria and a 24-year fight for justice</span>,\n",
       " <span class=\"js-headline-text\">Thirteen children have been shot dead in St Louis, Missouri. Why?</span>,\n",
       " <span class=\"js-headline-text\">The strange world of TikTok: viral videos and Chinese censorship</span>,\n",
       " <span class=\"js-headline-text\">Reality TV, social media and living your life online with Jia Tolentino</span>,\n",
       " <span class=\"js-headline-text\">Boris Johnson’s Brexit speech: preparing for an election</span>,\n",
       " <span class=\"js-headline-text\">Boris Johnson and the Jennifer Arcuri allegations</span>,\n",
       " <span class=\"js-headline-text\">Could this impeachment inquiry end Trump’s presidency?</span>,\n",
       " <span class=\"js-headline-text\">Is it over for Justin Trudeau?</span>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_read.select(\"span.js-headline-text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get only the content of the elements\n",
    "<br>➡  Use a `for` loop\n",
    "<br>➡  Use `print`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The five brothers forced apart by the war in Syria\n",
      "Naomi Klein on how politics can solve the climate crisis\n",
      "Are Fox News and Donald Trump falling out of love?\n",
      "Is this the end of the road for remainers?\n",
      "How did a town in West Virginia become the opioid capital of the US?\n",
      "Naming and shaming the polluters\n",
      "Will parliament vote for a Brexit deal?\n",
      "On the frontline as US troops leave northern Syria\n",
      "Hong Kong: the story of one protester\n",
      "What is the truth about vaping?\n",
      "A fatal crash and the problem of diplomatic immunity\n",
      "Brexit and the Irish border: is there a solution?\n",
      "Shell, Nigeria and a 24-year fight for justice\n",
      "Thirteen children have been shot dead in St Louis, Missouri. Why?\n",
      "The strange world of TikTok: viral videos and Chinese censorship\n",
      "Reality TV, social media and living your life online with Jia Tolentino\n",
      "Boris Johnson’s Brexit speech: preparing for an election\n",
      "Boris Johnson and the Jennifer Arcuri allegations\n",
      "Could this impeachment inquiry end Trump’s presidency?\n",
      "Is it over for Justin Trudeau?\n"
     ]
    }
   ],
   "source": [
    "for headline in website_read.select(\"span.js-headline-text\"):\n",
    "    print(headline.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>➡  Use a `for` loop\n",
    "<br>➡  save the elements in a list using `append`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for headline in website_read.select(\"span.js-headline-text\"):\n",
    "    data.append(headline.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>➡  Use another `for` loop to loop through the pages\n",
    "<br>➡ **pro tip**: use the `range()` function\n",
    "<br>➡ **Important**: we need to request, open and read new pages every time. What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for page in range(1,6):\n",
    "    URL = \"https://www.theguardian.com/news/series/todayinfocus?page=\" + str(page)\n",
    "\n",
    "    website_request = requests.get(URL)\n",
    "    website_content = website_request.text\n",
    "    website_read = bs(website_content)\n",
    "    \n",
    "    for headline in website_read.select(\"span.js-headline-text\"):\n",
    "        data.append(headline.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>➡  save the list as a csv using `pandas.DataFrame(list).to_csv(\"filename.csv\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(data).to_csv(\"headlines.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPER #2 : focus on selecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're gonna scrape the https://www.purehelp.no website. Click on the link to open it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download and read the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first steps are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.purehelp.no/m/solrSearch/search/a/1/Turnover_mer_enn_100_millioner/County_Svalbard/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_request = requests.get(URL)\n",
    "website_content = website_request.text\n",
    "website_read = bs(website_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scrape the company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* name\n",
    "* sector\n",
    "* location\n",
    "* turnovers\n",
    "* link to the details page\n",
    "\n",
    "Use a `for` loop<br>Make a `dictionary` to store the company information. <br> Make a `list` to store these dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use:\n",
    "<br>➡ `.select()` : select the elements we want to get based on their tags or attributes\n",
    "<br>➡ `.get()` : get an attribute value\n",
    "<br>➡ `.text` : get the content\n",
    "<br>➡ `tag[attribute^='value']` : get the tag where the attribute begins with some text\n",
    "<br>➡ `tag:nth-of-type(n)` : select a tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for company in website_read.select(\".cRL li\"):\n",
    "    company_details = {}\n",
    "    \n",
    "    company_details[\"name\"] = company.select(\"a\")[0].get(\"title\")\n",
    "    company_details[\"link\"] = company.select(\"a\")[0].get(\"href\")\n",
    "    company_details[\"sector\"] = company.select(\".d-md-none\")[0].text\n",
    "    company_details[\"location\"] = company.select(\"div[title^='Lokalisert'] span:nth-of-type(1)\")[0].text\n",
    "    company_details[\"turnover\"] = company.select(\"div[title^='Omsetning'] span:nth-of-type(2)\")[0].text\n",
    "    \n",
    "    data.append(company_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(data).to_csv(\"companies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Thank you for your attention!\n",
    "I'd be happy if you [leave me some feedback](https://goo.gl/forms/OtuNECgexYSyJGjh1) for this session so I can make it better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
